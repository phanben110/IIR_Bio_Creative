{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Read the text file into a DataFrame\n",
    "pair_relation_best = pd.read_csv('/Users/benphan/NCKU/IIR-Lab/BioCreative/6_10_final/TestSet/task1_finalPerformance/pair_relation_best.txt', sep='\\t')\n",
    "\n",
    "# Now, pair_relation_best_df contains the data from the text file\n",
    "unique_pair_relation = pd.read_csv(\"/Users/benphan/NCKU/IIR-Lab/BioCreative/6_10_final/TestSet/unique_pair_relation.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pair_relation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pair_relation[\"Identity_Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_relation_best.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # file_path = \"/Users/benphan/NCKU/IIR-Lab/BioCreative/Data/Demo_Probability.pubtator\"\n",
    "# #file_path = \"/Users/benphan/NCKU/IIR-Lab/BioCreative/Data/add_pair_entities_All_no_none_novel.pubtator\"\n",
    "# dir = \"/Users/benphan/NCKU/IIR-Lab/BioCreative/6_10_final/TestSet/Subtask1_Submission\"\n",
    "# # Initialize data collection list\n",
    "# list_file = os.listdir(dir)\n",
    "\n",
    "# list_data = []\n",
    "# for file_path in list_file: \n",
    "#     file_path = os.path.join(dir, file_path)  \n",
    "# # Open and process the file\n",
    "#     with open(file_path, 'r') as file:\n",
    "#         for line in file:\n",
    "#             fields = line.strip().split('\\t')\n",
    "#             if len(fields) == 6:\n",
    "#                 list_data.append([fields[4], fields[5]])\n",
    "\n",
    "# unique_pair_relation = pd.DataFrame(list_data, columns=[\"Identity_Type\", \"Identifier\"])\n",
    "# # Assuming you have a DataFrame called unique_pair_relation\n",
    "# # Remove rows with duplicate \"Identifier\" values\n",
    "# unique_pair_relation = unique_pair_relation.drop_duplicates(subset=\"Identifier\")\n",
    "\n",
    "# # Reset the index of the resulting DataFrame\n",
    "# unique_pair_relation = unique_pair_relation.reset_index(drop=True)\n",
    "# # Save the unique_pair_relation DataFrame to a text file\n",
    "\n",
    "# split_rows = []\n",
    "# for index, row in unique_pair_relation.iterrows():\n",
    "#     identifiers = row[\"Identifier\"].split(\",\")  # Split the comma-separated identifiers\n",
    "#     for identifier in identifiers:\n",
    "#         split_rows.append([row[\"Identity_Type\"], identifier])\n",
    "\n",
    "# # Create a new DataFrame with the split rows\n",
    "# new_unique_pair_relation = pd.DataFrame(split_rows, columns=[\"Identity_Type\", \"Identifier\"])\n",
    "# new_unique_pair_relation.drop_duplicates(subset=\"Identifier\") \n",
    "# new_unique_pair_relation = new_unique_pair_relation.reset_index(drop=True)\n",
    "# new_unique_pair_relation.to_csv('/Users/benphan/NCKU/IIR-Lab/BioCreative/6_10_final/TestSet/unique_pair_relation.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # file_path = \"/Users/benphan/NCKU/IIR-Lab/BioCreative/Data/Demo_Probability.pubtator\"\n",
    "# #file_path = \"/Users/benphan/NCKU/IIR-Lab/BioCreative/Data/add_pair_entities_All_no_none_novel.pubtator\"\n",
    "# dir = \"/Users/benphan/NCKU/IIR-Lab/BioCreative/6_10_final/TestSet/Subtask1_Submission\"\n",
    "# # Initialize data collection list\n",
    "# list_file = os.listdir(dir)\n",
    "# list_file.sort()\n",
    "\n",
    "# data_frame = []\n",
    "# for file_path in list_file: \n",
    "#     list_data = []\n",
    "#     file_path = os.path.join(dir, file_path)  \n",
    "# # Open and process the file\n",
    "#     with open(file_path, 'r') as file:\n",
    "\n",
    "#         for line in file:\n",
    "#             fields = line.strip().split('\\t')\n",
    "#             if len(fields) == 5:\n",
    "#                 list_data.append([fields[0], fields[1], fields[2], fields[3], fields[4] ])\n",
    "#     data_frame.append(pd.DataFrame(list_data, columns=[\"doc_id\", \"Relation_Type\", \"Identifier_1\", \"Identifier_2\", \"Novelty\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming you have a DataFrame called unique_pair_relation\n",
    "\n",
    "# def gen_format_relation_type(Identifier_1, Identifier_2, Relation_Type):\n",
    "#   # Use .loc to filter the DataFrame by the specified Identifier\n",
    "#   result1 = unique_pair_relation.loc[unique_pair_relation[\"Identifier\"] == Identifier_1, \"Identity_Type\"].iloc[0]\n",
    "\n",
    "#   result2 = unique_pair_relation.loc[unique_pair_relation[\"Identifier\"] == Identifier_2, \"Identity_Type\"].iloc[0]\n",
    "\n",
    "#   output1 = result1 + \"|\" + result2 \n",
    "\n",
    "#   return output1 + \"|\" + Relation_Type + \":\"  \n",
    "# for i in range(4): \n",
    "#   data_frame[i][['New_Column_1', 'New_Column_2']] = data_frame[i].apply(lambda row: gen_format_relation_type(row['Identifier_1'], row['Identifier_2'], row['Relation_Type']), axis=1, result_type='expand')\n",
    "\n",
    "# for i in range(4):\n",
    "#   data_frame[i].to_csv(f'/Users/benphan/NCKU/IIR-Lab/BioCreative/6_10_final/TestSet/Subtask1_add_2_column/Updated_Subtask1_Run{i+1}_Add_2_Column.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame called unique_pair_relation\n",
    "# def gen_format_relation_type(Identifier_1, Identifier_2, Relation_Type):\n",
    "#     # Use .loc to filter the DataFrame by the specified Identifier\n",
    "#     result1 = unique_pair_relation.loc[unique_pair_relation[\"Identifier\"] == Identifier_1, \"Identity_Type\"].iloc[0]\n",
    "#     result2 = unique_pair_relation.loc[unique_pair_relation[\"Identifier\"] == Identifier_2, \"Identity_Type\"].iloc[0]\n",
    "\n",
    "#     # Define the mappings\n",
    "#     mappings = {\n",
    "#         \"DiseaseOrPhenotypicFeature|ChemicalEntity\": \"ChemicalEntity|DiseaseOrPhenotypicFeature\",\n",
    "#         \"GeneOrGeneProduct|ChemicalEntity\": \"ChemicalEntity|GeneOrGeneProduct\",\n",
    "#         \"SequenceVariant|ChemicalEntity\": \"ChemicalEntity|SequenceVariant\",\n",
    "#         \"GeneOrGeneProduct|DiseaseOrPhenotypicFeature\": \"DiseaseOrPhenotypicFeature|GeneOrGeneProduct\",\n",
    "#         \"SequenceVariant|DiseaseOrPhenotypicFeature\": \"DiseaseOrPhenotypicFeature|SequenceVariant\"\n",
    "#     }\n",
    "\n",
    "#     # Check if the combination needs to be mapped\n",
    "#     combination = f\"{result1}|{result2}\"\n",
    "#     if combination in mappings:\n",
    "#         output1 = mappings[combination]\n",
    "#     else:\n",
    "#         output1 = combination\n",
    "\n",
    "#     return output1 + \"|\" + Relation_Type + \":\"\n",
    "\n",
    "# for i in range(4): \n",
    "#   data_frame[i]['New_Column_1'] = data_frame[i].apply(lambda row: gen_format_relation_type(row['Identifier_1'], row['Identifier_2'], row['Relation_Type']), axis=1, result_type='expand')\n",
    "\n",
    "# for i in range(4):\n",
    "#   data_frame[i].to_csv(f'/Users/benphan/NCKU/IIR-Lab/BioCreative/6_10_final/TestSet/Subtask1_add_2_column/Updated_Subtask1_Run{i+1}_Add_2_Column.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/Users/benphan/NCKU/IIR-Lab/BioCreative/6_10_final/TestSet/Subtask1_add_2_column\"\n",
    "list_file_data = os.listdir(input_dir) \n",
    "list_file_data.sort()\n",
    "data_frame = [None,None,None,None]\n",
    "for i in range(4):\n",
    "  data_frame[i] = pd.read_csv(os.path.join(input_dir, list_file_data[i]), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame[0][\"New_Column_1\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame[0][\"Relation_Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_relation_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_relation = \"ChemicalEntity|ChemicalEntity|Association:\"\n",
    "def get_name_run(pair_relation):\n",
    "  try: \n",
    "    return pair_relation_best.loc[pair_relation_best[\"Relation Type\"] == pair_relation, \"name_run\"].iloc[0]\n",
    "  except: \n",
    "    return \"base_best_run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair_relation = \"ChemicalEntity|ChemicalEntity|Association\"\n",
    "get_name_run(pair_relation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):  \n",
    "  data_frame[i]['name_run'] = data_frame[i]['New_Column_1'].apply(get_name_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame[3][\"name_run\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame_run1 = data_frame[0].loc[data_frame[0][\"name_run\"] == \"run1\"]\n",
    "data_frame_run1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "data_frame_run2 = data_frame[1].loc[data_frame[1][\"name_run\"] == \"run2\"]\n",
    "data_frame_run2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "data_frame_run3 = data_frame[2].loc[data_frame[2][\"name_run\"] == \"run3\"]\n",
    "data_frame_run3.reset_index(drop=True, inplace=True)\n",
    "\n",
    "data_frame_run4 = data_frame[3].loc[data_frame[3][\"name_run\"] == \"run4\"]\n",
    "data_frame_run4.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame_run1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame_run2[\"name_run\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames_to_merge = [data_frame_run1, data_frame_run2, data_frame_run3, data_frame_run4]\n",
    "\n",
    "# Concatenate the DataFrames along the rows (axis=0)\n",
    "data_frame_final_1 = pd.concat(data_frames_to_merge, axis=0, ignore_index=True)\n",
    "data_frame_final_1.sort_values(by='doc_id', inplace=True)\n",
    "data_frame_final_1.reset_index(drop=True, inplace=True)\n",
    "data_frame_final_1.drop(columns=[\"New_Column_1\", \"name_run\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame_final_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_relation_type(doc_id): \n",
    "  doc_id = int(doc_id)\n",
    "  data = data_frame_final_1.loc[data_frame_final_1[\"doc_id\"] == doc_id].values.tolist()\n",
    "  if len(data) > 0: \n",
    "    return [[str(item) for item in sublist] for sublist in data]\n",
    "  else : \n",
    "    return [['']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_relation_type(34189746)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame_final_1.to_csv('/Users/benphan/NCKU/IIR-Lab/BioCreative/6_10_final/TestSet/data_relation_pair/data_frame_1.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36713719\n",
      "['']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_path = \"/Users/benphan/NCKU/IIR-Lab/BioCreative/6_10_final/TestSet/Subtask1_Submission/Updated_Subtask1_Run1.pubtator\"\n",
    "\n",
    "# Step 1: Open the file\n",
    "documents = []\n",
    "entities = []\n",
    "pair_entities = []\n",
    "id_document = 0 \n",
    "raw_data = []\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    # Step 2: Read and process the contents\n",
    "for i, line in enumerate(lines):\n",
    "    fields = line.strip().split('\\t')\n",
    "    if  i == 0 and '|t|' in fields[0]:\n",
    "        position = fields[0].find('|t|')\n",
    "        id_document = fields[0][:position]\n",
    "        raw_data.append(fields)  \n",
    "        print(id_document) \n",
    "    elif i == len(lines) - 1:\n",
    "        raw_data.append(fields) \n",
    "        documents.append(raw_data)\n",
    "        print(fields)\n",
    "    elif '|t|' in fields[0]:\n",
    "        position = fields[0].find('|t|')\n",
    "        id_document = fields[0][:position]\n",
    "        documents.append(raw_data)\n",
    "        raw_data = [] \n",
    "        raw_data.append(fields) \n",
    "    elif '|a|' in fields[0]:\n",
    "        position = fields[0].find('|a|')\n",
    "        if id_document == fields[0][:position] : \n",
    "            raw_data.append(fields)  \n",
    "    elif id_document == fields[0]: \n",
    "        raw_data.append(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['36291918', '1499', '1505', 'cancer', 'DiseaseOrPhenotypicFeature', 'D009369']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_documents = []\n",
    "\n",
    "for i, document in enumerate(documents):\n",
    "  new_document = []\n",
    "  for j, fields in enumerate(document):\n",
    "    if len(fields) == 5:\n",
    "      pass \n",
    "    else: \n",
    "      new_document.append(fields)\n",
    "  new_documents.append(new_document)\n",
    "new_documents[-1].pop(-1)\n",
    "new_documents[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_ids = []\n",
    "id_document = \"\"\n",
    "for i, document_new in enumerate(new_documents):\n",
    "  for j, fields in enumerate(document_new):\n",
    "      if '|t|' in fields[0]:\n",
    "          position = fields[0].find('|t|')\n",
    "          id_document = fields[0][:position]\n",
    "          datas = export_relation_type(id_document)  \n",
    "          if len(datas) > 0:\n",
    "            for data in datas:\n",
    "              new_documents[i].append(data)   \n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_new = []\n",
    "for document in new_documents:\n",
    "    for i, fields in enumerate(document):\n",
    "       line = \"\"\n",
    "       for j, field in enumerate(fields):\n",
    "          if j == 0: \n",
    "             line = line + field    \n",
    "          else: \n",
    "            line = line + \"\\t\" + field\n",
    "       line = line + \"\\n\" \n",
    "       lines_new.append(line) \n",
    "    lines_new.append('\\n')\n",
    "\n",
    "with open(\"/Users/benphan/NCKU/IIR-Lab/BioCreative/6_10_final/TestSet/Final_Submit_Subtask1/subtask1_process_statistics_run1.pubtator\", \"w\") as file: \n",
    "  file.writelines(lines_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
