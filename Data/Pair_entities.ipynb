{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/benphan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11843\n",
      "6409\n",
      "Data has been successfully saved to /Users/benphan/NCKU/IIR-Lab/BioCreative/NewData_Add_Sentence/bc8_biored_task1_val_relation.csv\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import os\n",
    "\n",
    "list_file = os.listdir('/Users/benphan/NCKU/IIR-Lab/BioCreative/NewData')\n",
    "preprocess_datas = [] \n",
    "for file_path in list_file:\n",
    "    output_path = os.path.join('/Users/benphan/NCKU/IIR-Lab/BioCreative/NewData_Add_Sentence', f\"{file_path[:-9]}_relation.csv\") \n",
    "    file_path = os.path.join('/Users/benphan/NCKU/IIR-Lab/BioCreative/NewData', file_path)  \n",
    "\n",
    "\n",
    "    # Step 1: Open the file\n",
    "    rawDatas = [] \n",
    "    text =  \"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        preprocess = []\n",
    "        begin = True\n",
    "        # Step 2: Read and process the contents\n",
    "        for line in file:\n",
    "            fields = line.strip().split('\\t')\n",
    "            if len(fields) == 5:\n",
    "                preprocess_datas.append(fields[1:]) \n",
    "            #  pri\n",
    "                # preprocess.append(fields) \n",
    "unique_data = []\n",
    "\n",
    "for sublist in preprocess_datas:\n",
    "    # If the sublist is not in unique_ben, add it\n",
    "    if sublist not in unique_data:\n",
    "        unique_data.append(sublist)\n",
    "\n",
    "print(len(preprocess_datas)) \n",
    "print(len(unique_data))\n",
    "with open(\"distinct_all_data.csv\", 'w') as file:\n",
    "    for data in unique_data:\n",
    "        if (len(data) == 4):\n",
    "            line = '\\t'.join(data) + '\\n'\n",
    "            file.write(line)\n",
    "\n",
    "print(f'Data has been successfully saved to {output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BC8_BioRED_Task1_Doc500\n",
      "['BC8_BioRED_Task1_Doc1499', 'Comparison', 'C558933', 'D000326', 'Novel']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_path = \"/Users/benphan/NCKU/IIR-Lab/BioCreative/Data/all_no_none_novel_add_groundtruth.pubtator\"\n",
    "\n",
    "# Step 1: Open the file\n",
    "documents = []\n",
    "entities = []\n",
    "pair_entities = []\n",
    "id_document = 0 \n",
    "raw_data = []\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    # Step 2: Read and process the contents\n",
    "for i, line in enumerate(lines):\n",
    "    fields = line.strip().split('\\t')\n",
    "    if  i == 0 and '|t|' in fields[0]:\n",
    "        position = fields[0].find('|t|')\n",
    "        id_document = fields[0][:position]\n",
    "        raw_data.append(fields)  \n",
    "        print(id_document) \n",
    "    elif i == len(lines) - 1:\n",
    "        raw_data.append(fields) \n",
    "        documents.append(raw_data)\n",
    "        print(fields)\n",
    "    elif '|t|' in fields[0]:\n",
    "        position = fields[0].find('|t|')\n",
    "        id_document = fields[0][:position]\n",
    "        documents.append(raw_data)\n",
    "        raw_data = [] \n",
    "        raw_data.append(fields) \n",
    "    elif '|a|' in fields[0]:\n",
    "        position = fields[0].find('|a|')\n",
    "        if id_document == fields[0][:position] : \n",
    "            raw_data.append(fields)  \n",
    "    elif id_document == fields[0]: \n",
    "        raw_data.append(fields)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1687\n"
     ]
    }
   ],
   "source": [
    "entities = []\n",
    "count = 0\n",
    "for i, document in enumerate(documents):\n",
    "    entity = []\n",
    "    for fields in document: \n",
    "        if len(fields) == 6: \n",
    "            entity.append(fields[5])\n",
    "    entities.append(entity)\n",
    "\n",
    "    #check pair entities in ground truth\n",
    "    pair_entities = [] \n",
    "    for j, item in enumerate(entity):\n",
    "        for distict_data in unique_data: \n",
    "            if(item == distict_data[1]) or (item == distict_data[2]):\n",
    "                if (distict_data[1] in entity) and (distict_data[2] in entity) : \n",
    "                    pair_entities.append(distict_data)\n",
    "    \n",
    "    unique_pairs = []\n",
    "    # Iterate through the original list\n",
    "    for pair in pair_entities:\n",
    "        # If the pair is not already in the unique_pairs list, add it\n",
    "        if pair not in unique_pairs:\n",
    "            unique_pairs.append(pair)\n",
    "\n",
    "    for j, pair in enumerate(unique_pairs): \n",
    "        if 1 == 1: \n",
    "            for fields in document: \n",
    "                if len(fields) == 5:\n",
    "                    if (fields[2] == pair[1] and fields[3] == pair[2]) or (fields[1] == pair[2] and fields[3] == pair[1]): \n",
    "                        unique_pairs.remove(pair)\n",
    "    unique_pairs = [list(x) for x in {tuple(sublist) for sublist in unique_pairs}] \n",
    "    for pair in unique_pairs:\n",
    "        documents[i].append([document[2][0],pair[0],pair[1],pair[2],pair[3]])  \n",
    "        count += 1   \n",
    "\n",
    "     \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ben = [2,3,4,5,5]\n",
    "3 in ben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_new = []\n",
    "for document in documents:\n",
    "    for i, fields in enumerate(document):\n",
    "       line = \"\"\n",
    "       for j, field in enumerate(fields):\n",
    "          if j == 0: \n",
    "             line = line + field    \n",
    "          else: \n",
    "            line = line + \"\\t\" + field\n",
    "       line = line + \"\\n\" \n",
    "       lines_new.append(line) \n",
    "    lines_new.append('\\n')\n",
    "\n",
    "with open(\"/Users/benphan/NCKU/IIR-Lab/BioCreative/Data/add_pair_entities_All_no_none_novel.pubtator\", \"w\") as file: \n",
    "  file.writelines(lines_new)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
